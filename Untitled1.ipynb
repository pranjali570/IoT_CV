{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required packages\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mention the installed location of Tesseract-OCR in your system\n",
    "pytesseract.pytesseract.tesseract_cmd = 'C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('ocr-a-font-sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explain\n",
      "that\n",
      "Stuff!\n",
      "01234547890\n",
      "\f",
      "\n"
     ]
    }
   ],
   "source": [
    "print(pytesseract.image_to_string(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['E', '56', '146', '73', '173', '0']\n",
      "['x', '82', '146', '99', '166', '0']\n",
      "['p', '108', '139', '125', '167', '0']\n",
      "['l', '136', '146', '150', '173', '0']\n",
      "['a', '160', '146', '176', '166', '0']\n",
      "['i', '188', '146', '202', '175', '0']\n",
      "['n', '212', '146', '229', '166', '0']\n",
      "['t', '95', '100', '112', '126', '0']\n",
      "['h', '121', '100', '138', '127', '0']\n",
      "['a', '147', '100', '163', '120', '0']\n",
      "['t', '173', '100', '190', '126', '0']\n",
      "['S', '69', '54', '86', '81', '0']\n",
      "['t', '95', '54', '112', '80', '0']\n",
      "['u', '121', '54', '138', '74', '0']\n",
      "['f', '148', '54', '163', '81', '0']\n",
      "['f', '174', '54', '189', '81', '0']\n",
      "['!', '205', '54', '210', '81', '0']\n",
      "['0', '4', '8', '21', '35', '0']\n",
      "['1', '30', '8', '47', '35', '0']\n",
      "['2', '56', '8', '73', '35', '0']\n",
      "['3', '82', '8', '98', '35', '0']\n",
      "['4', '109', '8', '124', '35', '0']\n",
      "['5', '133', '8', '150', '35', '0']\n",
      "['4', '160', '8', '177', '35', '0']\n",
      "['7', '186', '8', '203', '35', '0']\n",
      "['8', '212', '8', '229', '35', '0']\n",
      "['9', '238', '8', '255', '35', '0']\n",
      "['0', '264', '8', '281', '35', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detecting all characters\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_boxes(img)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    print(b)\n",
    "    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg-y), (w, hImg-h), (0,0,255),1)\n",
    "    cv2.putText(img, b[0], (x,hImg-y-35), cv2.FONT_HERSHEY_COMPLEX,1,(50,50,225),2)\n",
    "\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('ocr-a-font-sample.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '4', '8', '21', '35', '0']\n",
      "['1', '30', '8', '47', '35', '0']\n",
      "['2', '56', '8', '73', '35', '0']\n",
      "['3', '82', '8', '98', '35', '0']\n",
      "['4', '109', '8', '124', '35', '0']\n",
      "['5', '133', '8', '150', '35', '0']\n",
      "['4', '160', '8', '177', '35', '0']\n",
      "['7', '186', '8', '203', '35', '0']\n",
      "['8', '212', '8', '229', '35', '0']\n",
      "['9', '238', '8', '255', '35', '0']\n",
      "['0', '264', '8', '281', '35', '0']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detecting numbers only\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "cong = r'--oem 3 --psm 6 outputbase digits'\n",
    "boxes = pytesseract.image_to_boxes(img, config=cong)\n",
    "for b in boxes.splitlines():\n",
    "    b = b.split(' ')\n",
    "    print(b)\n",
    "    x,y,w,h = int(b[1]),int(b[2]),int(b[3]),int(b[4])\n",
    "    cv2.rectangle(img, (x,hImg-y), (w, hImg-h), (0,0,255),1)\n",
    "    cv2.putText(img, b[0], (x,hImg-y-35), cv2.FONT_HERSHEY_COMPLEX,1,(50,50,225),2)\n",
    "\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1', '1', '0', '0', '0', '0', '0', '0', '306', '103', '-1']\n",
      "['2', '1', '1', '0', '0', '0', '9', '8', '292', '85', '-1']\n",
      "['3', '1', '1', '1', '0', '0', '9', '8', '292', '39', '-1']\n",
      "['4', '1', '1', '1', '1', '0', '41', '8', '241', '17', '-1']\n",
      "['5', '1', '1', '1', '1', '1', '41', '8', '34', '14', '95', 'the']\n",
      "['5', '1', '1', '1', '1', '2', '92', '8', '60', '17', '96', 'quick']\n",
      "['5', '1', '1', '1', '1', '3', '170', '8', '60', '14', '96', 'brown']\n",
      "['5', '1', '1', '1', '1', '4', '248', '9', '34', '13', '96', 'fox']\n",
      "['4', '1', '1', '1', '2', '0', '9', '29', '292', '18', '-1']\n",
      "['5', '1', '1', '1', '2', '1', '9', '29', '60', '18', '96', 'jumps']\n",
      "['5', '1', '1', '1', '2', '2', '86', '33', '47', '10', '96', 'over']\n",
      "['5', '1', '1', '1', '2', '3', '150', '30', '35', '13', '97', 'the']\n",
      "['5', '1', '1', '1', '2', '4', '203', '30', '46', '17', '96', 'lazy']\n",
      "['5', '1', '1', '1', '2', '5', '266', '30', '35', '17', '96', 'dog']\n",
      "['3', '1', '1', '2', '0', '0', '9', '58', '292', '35', '-1']\n",
      "['4', '1', '1', '2', '1', '0', '34', '58', '241', '14', '-1']\n",
      "['5', '1', '1', '2', '1', '1', '34', '58', '35', '14', '95', 'THE']\n",
      "['5', '1', '1', '2', '1', '2', '86', '58', '60', '14', '96', 'QUICK']\n",
      "['5', '1', '1', '2', '1', '3', '163', '58', '61', '14', '96', 'BROWN']\n",
      "['5', '1', '1', '2', '1', '4', '240', '58', '35', '14', '96', 'FOX']\n",
      "['4', '1', '1', '2', '2', '0', '9', '79', '292', '14', '-1']\n",
      "['5', '1', '1', '2', '2', '1', '9', '79', '60', '14', '94', 'JUMPS']\n",
      "['5', '1', '1', '2', '2', '2', '86', '79', '47', '14', '96', 'OVER']\n",
      "['5', '1', '1', '2', '2', '3', '150', '79', '35', '14', '96', 'THE']\n",
      "['5', '1', '1', '2', '2', '4', '202', '79', '48', '14', '96', 'LAZY']\n",
      "['5', '1', '1', '2', '2', '5', '266', '79', '35', '14', '84', 'DOG']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#detecting words\n",
    "\n",
    "hImg,wImg,_ = img.shape\n",
    "boxes = pytesseract.image_to_data(img)\n",
    "count = 0;\n",
    "for b in boxes.splitlines():\n",
    "    if count !=0:\n",
    "        b = b.split()\n",
    "        print(b)\n",
    "        if len(b)==12:\n",
    "            x,y,w,h = int(b[6]), int(b[7]), int(b[8]), int(b[9])\n",
    "            cv2.rectangle(img, (x,y), (w+x,h+y), (0,0,255),1)\n",
    "            cv2.putText(img, b[11], (x,y), cv2.FONT_HERSHEY_COMPLEX, 1, (50,50,255),2)\n",
    "    count = count + 1\n",
    "\n",
    "#to display image\n",
    "cv2.imshow('frame', img)\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image from which text needs to be extracted\n",
    "\n",
    "img = cv2.imread('download.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the image to RGB scale\n",
    "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to recognize text and save the content in text file\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# Performing OTSU threshold\n",
    "ret, thresh1 = cv2.threshold(gray, 0, 255, cv2.THRESH_OTSU | cv2.THRESH_BINARY_INV)\n",
    "\n",
    "# Specify structure shape and kernel size.\n",
    "# Kernel size increases or decreases the area\n",
    "# of the rectangle to be detected.\n",
    "# A smaller value like (10, 10) will detect\n",
    "# each word instead of a sentence.\n",
    "rect_kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (18, 18))\n",
    "\n",
    "# Appplying dilation on the threshold image\n",
    "dilation = cv2.dilate(thresh1, rect_kernel, iterations=1)\n",
    "\n",
    "# Finding contours\n",
    "contours, hierarchy = cv2.findContours(dilation, cv2.RETR_EXTERNAL,\n",
    "                                       cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "# Creating a copy of image\n",
    "im2 = img.copy()\n",
    "\n",
    "# A text file is created and flushed\n",
    "file = open(\"recognized.txt\", \"w+\")\n",
    "file.write(\"\")\n",
    "file.close()\n",
    "\n",
    "# Looping through the identified contours\n",
    "# Then rectangular part is cropped and passed on\n",
    "# to pytesseract for extracting text from it\n",
    "# Extracted text is then written into the text file\n",
    "for cnt in contours:\n",
    "    x, y, w, h = cv2.boundingRect(cnt)\n",
    "\n",
    "    # Drawing a rectangle on copied image\n",
    "    rect = cv2.rectangle(im2, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "    # Cropping the text block for giving input to OCR\n",
    "    cropped = im2[y:y + h, x:x + w]\n",
    "\n",
    "    # Open the file in append mode\n",
    "    file = open(\"recognized.txt\", \"a\")\n",
    "\n",
    "    # Apply OCR on the cropped image\n",
    "    text = pytesseract.image_to_string(cropped)\n",
    "\n",
    "    # Appending the text into file\n",
    "    file.write(text)\n",
    "    file.write(\"\\n\")\n",
    "\n",
    "    # Close the file\n",
    "    file.close\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
